# Reducing Hallucinations in Abstractive Summarization

The original code is by Eliza Szczechla (GitHub handle `elsanns`) and was only modified slightly for our purpose.
Her code is available in this Colab notebook - 
https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb

It is also available here - https://github.com/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb

Our slightly modified version is made available here as bart.py (exported as a script).
Please also find the model weights after training for 15 epochs.
The checkpoints for the model can be found at this link:
https://drive.google.com/drive/folders/1g30uur8Ox1Hrf7dA_2Ege1rIOZpQe1Ga?usp=sharing
